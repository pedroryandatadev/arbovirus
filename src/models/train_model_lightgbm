import pandas as pd
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import LabelEncoder
from imblearn.under_sampling import RandomUnderSampler
from lightgbm import LGBMClassifier
from sklearn.metrics import accuracy_score, classification_report
from imblearn.pipeline import Pipeline

# Load data
df = pd.read_csv('data/processed/processed.csv')

# Input variables
X = df[['nu_idade', 'tp_sexo', 'febre', 'mialgia', 'cefaleia', 'vomito', 'nausea',
        'dor_costas', 'artralgia', 'petequia_n', 'dor_retro']]

# Target variable
y = df['tp_classificacao_final']

# Encode target variable
le_target = LabelEncoder()
y = le_target.fit_transform(y)

# Separate training and testing
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# Define the pipeline with balancing + model
pipeline = Pipeline(steps=[
    ('undersample', RandomUnderSampler(random_state=42)),
    ('lgbm', LGBMClassifier(
        objective='multiclass',
        num_class=len(le_target.classes_),
        random_state=42
    ))
])

# Grid of hyperparameters
param_grid = {
    'lgbm__n_estimators': [200, 500, 800],
    'lgbm__learning_rate': [0.01, 0.05, 0.1],
    'lgbm__max_depth': [-1, 5, 10],
    'lgbm__num_leaves': [15, 31, 50],
    'lgbm__subsample': [0.7, 0.85, 1.0],
    'lgbm__colsample_bytree': [0.7, 0.85, 1.0]
}

# Grid Search
grid_search = GridSearchCV(
    estimator=pipeline,
    param_grid=param_grid,
    scoring='accuracy',
    cv=3,
    verbose=1,
    n_jobs=-1
)

# Train the model with Grid Search and balancing
grid_search.fit(X_train, y_train)

# Best model
best_model = grid_search.best_estimator_

print('Best parameters found:')
print(grid_search.best_params_)

# Evaluate on test data
y_pred = best_model.predict(X_test)

print('\nAccuracy:', accuracy_score(y_test, y_pred))
print('\nRanking Report:')
print(classification_report(y_test, y_pred, target_names=le_target.classes_))